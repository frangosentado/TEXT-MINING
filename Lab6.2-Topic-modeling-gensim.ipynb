{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab6.2: Topic modeling using gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we demonstrate how LDA models can be built and applied using the *gensim* package.\n",
    "\n",
    "Credits:\n",
    "\n",
    "This notebook is an adaptation of a blog from Susan Li's:\n",
    "\n",
    "https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set we’ll use is a list of over one million news headlines published over a period of 15 years and can be downloaded from:\n",
    "\n",
    "https://www.kaggle.com/therohk/million-headlines/data\n",
    "\n",
    "We read the CSV file using the pandas framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#### Adapt the path below to point to your local copy of the data set\n",
    "data = pd.read_csv('./abcnews-date-text.csv');\n",
    "data_text = data[['headline_text']]\n",
    "data_text['index'] = data_text.index\n",
    "documents = data_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1244184\n",
      "                                       headline_text  index\n",
      "0  aba decides against community broadcasting lic...      0\n",
      "1     act fire witnesses must be aware of defamation      1\n",
      "2     a g calls for infrastructure protection summit      2\n",
      "3           air nz staff in aust strike for pay rise      3\n",
      "4      air nz strike to affect australian travellers      4\n"
     ]
    }
   ],
   "source": [
    "print(len(documents))\n",
    "print(documents[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the *gensim* package to build our LDA models from the data.\n",
    "Before building the model, we are going to preprocess the texts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing\n",
    "We will perform the following steps:\n",
    "\n",
    "* Tokenization: Split the text into sentences and the sentences into words. Lowercase the words and remove punctuation.\n",
    "* Words that have fewer than 3 characters are removed.\n",
    "* All stopwords are removed.\n",
    "* Words are lemmatized — words in third person are changed to first person and verbs in past and future tenses are changed into present.\n",
    "* Words are stemmed — words are reduced to their root form.\n",
    "\n",
    "In order to apply these processing steps, we first load the gensim and nltk libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/bebulcao/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    return lemmatizer.lemmatize(text)\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "           # result.append(token)\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original document: \n",
      "['ratepayers', 'group', 'wants', 'compulsory', 'local', 'govt', 'voting']\n",
      "\n",
      "\n",
      " tokenized and lemmatized document: \n",
      "['ratepayer', 'group', 'want', 'compulsory', 'local', 'govt', 'voting']\n"
     ]
    }
   ],
   "source": [
    "doc_sample = documents[documents['index'] == 4310].values[0][0]\n",
    "print('original document: ')\n",
    "words = []\n",
    "for word in doc_sample.split(' '):\n",
    "    words.append(word)\n",
    "print(words)\n",
    "print('\\n\\n tokenized and lemmatized document: ')\n",
    "print(preprocess(doc_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now apply the preprocessing to all the headlines and print the first 10 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          [decides, community, broadcasting, licence]\n",
       "1                         [witness, aware, defamation]\n",
       "2           [call, infrastructure, protection, summit]\n",
       "3                          [staff, aust, strike, rise]\n",
       "4              [strike, affect, australian, traveller]\n",
       "5               [ambitious, olsson, win, triple, jump]\n",
       "6          [antic, delighted, record, breaking, barca]\n",
       "7    [aussie, qualifier, stosur, waste, memphis, ma...\n",
       "8             [aust, address, security, council, iraq]\n",
       "9                       [australia, locked, timetable]\n",
       "Name: headline_text, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs = documents['headline_text'].map(preprocess)\n",
    "### print the first 10 results\n",
    "processed_docs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words on the Data set\n",
    "Create a dictionary from ‘processed_docs’ containing the number of times a word appears in the training set.\n",
    "We are going to use the *Dictionary* function to derive a dictionary with counts from the headlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 broadcasting\n",
      "1 community\n",
      "2 decides\n",
      "3 licence\n",
      "4 aware\n",
      "5 defamation\n",
      "6 witness\n",
      "7 call\n",
      "8 infrastructure\n",
      "9 protection\n",
      "10 summit\n"
     ]
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gensim filter_extremes\n",
    "Filter out tokens that appear in\n",
    "less than 15 documents (absolute number) or\n",
    "more than 0.5 documents (fraction of total corpus size, not absolute number).\n",
    "after the above two steps, keep only the first 100000 most frequent tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gensim doc2bow\n",
    "For each document we create a dictionary reporting how many words and how many times those words appear. \n",
    "Gensim provides the *doc2bow* function to create a BoW vector representation for a document.\n",
    "Save this to ‘bow_corpus’, then check our selected document earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(164, 1), (241, 1), (615, 1), (891, 1), (4173, 1), (4174, 1), (4175, 1)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "bow_corpus[4310]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preview Bag Of Words for our sample preprocessed document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 164 (\"govt\") appears 1 time.\n",
      "Word 241 (\"group\") appears 1 time.\n",
      "Word 615 (\"local\") appears 1 time.\n",
      "Word 891 (\"want\") appears 1 time.\n",
      "Word 4173 (\"compulsory\") appears 1 time.\n",
      "Word 4174 (\"ratepayer\") appears 1 time.\n",
      "Word 4175 (\"voting\") appears 1 time.\n"
     ]
    }
   ],
   "source": [
    "bow_doc_4310 = bow_corpus[4310]\n",
    "for i in range(len(bow_doc_4310)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_4310[i][0], \n",
    "                                               dictionary[bow_doc_4310[i][0]], \n",
    "bow_doc_4310[i][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF\n",
    "Create tf-idf model object using models.TfidfModel on ‘bow_corpus’ and save it to ‘tfidf’, then apply transformation to the entire corpus and call it ‘corpus_tfidf’. Finally we preview TF-IDF scores for our first document.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.6161125947380649),\n",
      " (1, 0.3308772069039591),\n",
      " (2, 0.5681053683635203),\n",
      " (3, 0.43379930266554434)]\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "from pprint import pprint\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running LDA using Bag of Words\n",
    "Train our lda model using gensim.models.LdaMulticore and save it to ‘lda_model’. This takes a while.\n",
    "Look at the documentation of *gensim* for further details:\n",
    "\n",
    "https://radimrehurek.com/gensim/models/ldamulticore.html\n",
    "\n",
    "As parameters, we pass the corpus data as BoW (a list of lists of tuples), the prefixed number of topics, the actual words and the number of passes and workers used for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=2, workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each topic, we will explore the words occuring in that topic and its relative weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.040*\"victoria\" + 0.035*\"case\" + 0.033*\"covid\" + 0.028*\"coronavirus\" + 0.024*\"child\" + 0.016*\"island\" + 0.016*\"scott\" + 0.011*\"border\" + 0.010*\"deal\" + 0.010*\"beach\"\n",
      "Topic: 1 \n",
      "Words: 0.024*\"canberra\" + 0.024*\"restriction\" + 0.023*\"life\" + 0.019*\"water\" + 0.016*\"police\" + 0.016*\"missing\" + 0.015*\"country\" + 0.014*\"claim\" + 0.014*\"concern\" + 0.014*\"farmer\"\n",
      "Topic: 2 \n",
      "Words: 0.039*\"sydney\" + 0.030*\"election\" + 0.017*\"lockdown\" + 0.012*\"andrew\" + 0.011*\"state\" + 0.011*\"commission\" + 0.011*\"president\" + 0.010*\"say\" + 0.009*\"biden\" + 0.009*\"liberal\"\n",
      "Topic: 3 \n",
      "Words: 0.043*\"queensland\" + 0.025*\"south\" + 0.017*\"north\" + 0.016*\"victorian\" + 0.015*\"australia\" + 0.015*\"indigenous\" + 0.015*\"morrison\" + 0.013*\"student\" + 0.013*\"west\" + 0.012*\"school\"\n",
      "Topic: 4 \n",
      "Words: 0.036*\"police\" + 0.030*\"woman\" + 0.027*\"court\" + 0.024*\"death\" + 0.024*\"donald\" + 0.019*\"murder\" + 0.017*\"people\" + 0.016*\"year\" + 0.015*\"charged\" + 0.015*\"face\"\n",
      "Topic: 5 \n",
      "Words: 0.029*\"government\" + 0.020*\"health\" + 0.015*\"tasmania\" + 0.014*\"plan\" + 0.013*\"federal\" + 0.012*\"say\" + 0.011*\"council\" + 0.010*\"care\" + 0.010*\"call\" + 0.010*\"regional\"\n",
      "Topic: 6 \n",
      "Words: 0.021*\"crash\" + 0.017*\"house\" + 0.015*\"bushfire\" + 0.015*\"dy\" + 0.014*\"adelaide\" + 0.011*\"climate\" + 0.011*\"darwin\" + 0.009*\"home\" + 0.009*\"road\" + 0.009*\"week\"\n",
      "Topic: 7 \n",
      "Words: 0.046*\"coronavirus\" + 0.027*\"covid\" + 0.019*\"news\" + 0.018*\"china\" + 0.017*\"australia\" + 0.016*\"record\" + 0.016*\"market\" + 0.015*\"australian\" + 0.013*\"live\" + 0.011*\"coast\"\n",
      "Topic: 8 \n",
      "Words: 0.022*\"national\" + 0.017*\"change\" + 0.015*\"premier\" + 0.015*\"return\" + 0.014*\"tasmanian\" + 0.013*\"work\" + 0.012*\"rural\" + 0.011*\"show\" + 0.011*\"park\" + 0.011*\"risk\"\n",
      "Topic: 9 \n",
      "Words: 0.041*\"trump\" + 0.019*\"vaccine\" + 0.017*\"australia\" + 0.015*\"test\" + 0.014*\"open\" + 0.013*\"world\" + 0.013*\"final\" + 0.012*\"royal\" + 0.010*\"interview\" + 0.009*\"pandemic\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you distinguish different topics using the words in each topic and their corresponding weights?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running LDA using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.016*\"news\" + 0.015*\"coronavirus\" + 0.014*\"covid\" + 0.011*\"country\" + 0.010*\"health\" + 0.010*\"rural\" + 0.008*\"restriction\" + 0.008*\"hour\" + 0.007*\"national\" + 0.006*\"federal\"\n",
      "Topic: 1 Word: 0.016*\"queensland\" + 0.013*\"coast\" + 0.012*\"coronavirus\" + 0.010*\"lockdown\" + 0.009*\"covid\" + 0.008*\"victoria\" + 0.008*\"gold\" + 0.008*\"south\" + 0.008*\"west\" + 0.007*\"weather\"\n",
      "Topic: 2 Word: 0.010*\"speaks\" + 0.010*\"climate\" + 0.006*\"june\" + 0.006*\"james\" + 0.006*\"george\" + 0.006*\"johnson\" + 0.005*\"award\" + 0.005*\"united\" + 0.005*\"drone\" + 0.005*\"tony\"\n",
      "Topic: 3 Word: 0.014*\"morrison\" + 0.010*\"thursday\" + 0.009*\"sport\" + 0.008*\"peter\" + 0.008*\"biden\" + 0.008*\"turnbull\" + 0.008*\"social\" + 0.007*\"august\" + 0.007*\"grandstand\" + 0.006*\"disability\"\n",
      "Topic: 4 Word: 0.016*\"donald\" + 0.011*\"vaccine\" + 0.011*\"coronavirus\" + 0.011*\"covid\" + 0.008*\"market\" + 0.007*\"border\" + 0.007*\"australian\" + 0.007*\"wall\" + 0.007*\"david\" + 0.007*\"finance\"\n",
      "Topic: 5 Word: 0.014*\"live\" + 0.012*\"drum\" + 0.009*\"andrew\" + 0.009*\"story\" + 0.008*\"government\" + 0.008*\"tuesday\" + 0.008*\"price\" + 0.006*\"coal\" + 0.006*\"outback\" + 0.005*\"facebook\"\n",
      "Topic: 6 Word: 0.017*\"police\" + 0.013*\"murder\" + 0.012*\"charged\" + 0.011*\"court\" + 0.010*\"death\" + 0.009*\"woman\" + 0.008*\"child\" + 0.008*\"charge\" + 0.007*\"missing\" + 0.007*\"alleged\"\n",
      "Topic: 7 Word: 0.016*\"interview\" + 0.010*\"crash\" + 0.010*\"friday\" + 0.009*\"pandemic\" + 0.008*\"extended\" + 0.007*\"daniel\" + 0.007*\"alan\" + 0.006*\"july\" + 0.006*\"dy\" + 0.005*\"prince\"\n",
      "Topic: 8 Word: 0.009*\"monday\" + 0.009*\"aged\" + 0.007*\"care\" + 0.006*\"september\" + 0.006*\"october\" + 0.006*\"say\" + 0.006*\"korea\" + 0.005*\"like\" + 0.005*\"australia\" + 0.005*\"human\"\n",
      "Topic: 9 Word: 0.026*\"trump\" + 0.011*\"australia\" + 0.009*\"final\" + 0.009*\"world\" + 0.006*\"hill\" + 0.006*\"cricket\" + 0.006*\"zealand\" + 0.006*\"australian\" + 0.005*\"open\" + 0.005*\"test\"\n"
     ]
    }
   ],
   "source": [
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=dictionary, passes=2, workers=4)\n",
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, can you distinguish different topics using the words in each topic and their corresponding weights? Do you observe any differences with the BoW version? Do these differences make sense given the information value weighing by the *tfidf* method?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance evaluation by classifying sample document using LDA Bag of Words model\n",
    "We will check where our test document would be classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ratepayer', 'group', 'want', 'compulsory', 'local', 'govt', 'voting']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs[4310]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Document 4310 is already represented in the correct way. We can directly pass it to our *lda_model* to get the similarity scores for each topic. We represent each topic by printing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.7306880950927734\t \n",
      "Topic: 0.029*\"government\" + 0.020*\"health\" + 0.015*\"tasmania\" + 0.014*\"plan\" + 0.013*\"federal\" + 0.012*\"say\" + 0.011*\"council\" + 0.010*\"care\" + 0.010*\"call\" + 0.010*\"regional\"\n",
      "\n",
      "Score: 0.16923071444034576\t \n",
      "Topic: 0.046*\"coronavirus\" + 0.027*\"covid\" + 0.019*\"news\" + 0.018*\"china\" + 0.017*\"australia\" + 0.016*\"record\" + 0.016*\"market\" + 0.015*\"australian\" + 0.013*\"live\" + 0.011*\"coast\"\n",
      "\n",
      "Score: 0.012510483153164387\t \n",
      "Topic: 0.022*\"national\" + 0.017*\"change\" + 0.015*\"premier\" + 0.015*\"return\" + 0.014*\"tasmanian\" + 0.013*\"work\" + 0.012*\"rural\" + 0.011*\"show\" + 0.011*\"park\" + 0.011*\"risk\"\n",
      "\n",
      "Score: 0.012510311789810658\t \n",
      "Topic: 0.043*\"queensland\" + 0.025*\"south\" + 0.017*\"north\" + 0.016*\"victorian\" + 0.015*\"australia\" + 0.015*\"indigenous\" + 0.015*\"morrison\" + 0.013*\"student\" + 0.013*\"west\" + 0.012*\"school\"\n",
      "\n",
      "Score: 0.01251023169606924\t \n",
      "Topic: 0.041*\"trump\" + 0.019*\"vaccine\" + 0.017*\"australia\" + 0.015*\"test\" + 0.014*\"open\" + 0.013*\"world\" + 0.013*\"final\" + 0.012*\"royal\" + 0.010*\"interview\" + 0.009*\"pandemic\"\n",
      "\n",
      "Score: 0.012510161846876144\t \n",
      "Topic: 0.024*\"canberra\" + 0.024*\"restriction\" + 0.023*\"life\" + 0.019*\"water\" + 0.016*\"police\" + 0.016*\"missing\" + 0.015*\"country\" + 0.014*\"claim\" + 0.014*\"concern\" + 0.014*\"farmer\"\n",
      "\n",
      "Score: 0.012510158121585846\t \n",
      "Topic: 0.040*\"victoria\" + 0.035*\"case\" + 0.033*\"covid\" + 0.028*\"coronavirus\" + 0.024*\"child\" + 0.016*\"island\" + 0.016*\"scott\" + 0.011*\"border\" + 0.010*\"deal\" + 0.010*\"beach\"\n",
      "\n",
      "Score: 0.012509948574006557\t \n",
      "Topic: 0.036*\"police\" + 0.030*\"woman\" + 0.027*\"court\" + 0.024*\"death\" + 0.024*\"donald\" + 0.019*\"murder\" + 0.017*\"people\" + 0.016*\"year\" + 0.015*\"charged\" + 0.015*\"face\"\n",
      "\n",
      "Score: 0.012509947642683983\t \n",
      "Topic: 0.039*\"sydney\" + 0.030*\"election\" + 0.017*\"lockdown\" + 0.012*\"andrew\" + 0.011*\"state\" + 0.011*\"commission\" + 0.011*\"president\" + 0.010*\"say\" + 0.009*\"biden\" + 0.009*\"liberal\"\n",
      "\n",
      "Score: 0.012509947642683983\t \n",
      "Topic: 0.021*\"crash\" + 0.017*\"house\" + 0.015*\"bushfire\" + 0.015*\"dy\" + 0.014*\"adelaide\" + 0.011*\"climate\" + 0.011*\"darwin\" + 0.009*\"home\" + 0.009*\"road\" + 0.009*\"week\"\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(lda_model[bow_corpus[4310]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our test document has the highest probability to be part of the topic that our model assigned, which is the accurate classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing our LDA model\n",
    "\n",
    "Now that we have a trained model let’s visualize the topics for interpretability. \n",
    "To do so, we’ll use a popular visualization package, *pyLDAvis* which is designed to help interactively with:\n",
    "\n",
    "1. Better understanding and interpreting individual topics, and\n",
    "2. Better understanding the relationships between the topics.\n",
    "\n",
    "For (1), you can manually select each topic to view its top most frequent and/or “relevant” terms, using different values of the λ parameter. This can help when you’re trying to assign a human interpretable name or “meaning” to each topic.\n",
    "For (2), exploring the Intertopic Distance Plot can help you learn about how topics relate to each other, including potential higher-level structure between groups of topics.\n",
    "\n",
    "You need to install *pyldavis* through the command line, following the instructions:\n",
    "\n",
    "https://anaconda.org/conda-forge/pyldavis\n",
    "\n",
    "WARNING: running the next cell takes a long time and you need some memory to run it. However, the result is spectacular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el2768311892900688611380815\" style=\"background-color:white;\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el2768311892900688611380815_data = {\"mdsDat\": {\"x\": [-0.08414033197368931, -0.04496249689027828, -0.13201675035367294, 0.3098616894547537, 0.2813674556566869, -0.04543376011055766, -0.12876884413250175, -0.11863508261400822, 0.09899645144970327, -0.13626833048643522], \"y\": [-0.26276998661224693, 0.22099933273556646, 0.12107885359496921, 0.03424827294645797, 0.06389906918053266, 0.11072766915539177, 0.059525006275456885, -0.17653775008613132, -0.23952894614817488, 0.0683584789581785], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [13.335514336800678, 10.899266792333595, 10.877421178445335, 10.589992666490195, 9.835678490747629, 9.796219274987854, 9.253429316981979, 8.59561387856688, 8.524494112450373, 8.292369952195482]}, \"tinfo\": {\"Term\": [\"coronavirus\", \"trump\", \"queensland\", \"sydney\", \"covid\", \"victoria\", \"police\", \"government\", \"case\", \"woman\", \"election\", \"court\", \"donald\", \"south\", \"death\", \"health\", \"child\", \"canberra\", \"restriction\", \"life\", \"crash\", \"news\", \"vaccine\", \"national\", \"murder\", \"australia\", \"china\", \"tasmania\", \"people\", \"water\", \"government\", \"health\", \"tasmania\", \"federal\", \"plan\", \"council\", \"care\", \"regional\", \"service\", \"aged\", \"speaks\", \"budget\", \"public\", \"announces\", \"review\", \"funding\", \"mental\", \"emergency\", \"aboriginal\", \"finance\", \"action\", \"hong\", \"housing\", \"briefing\", \"kong\", \"told\", \"stop\", \"expert\", \"patient\", \"project\", \"call\", \"minister\", \"hospital\", \"christmas\", \"say\", \"business\", \"worker\", \"change\", \"trump\", \"vaccine\", \"test\", \"final\", \"royal\", \"interview\", \"pandemic\", \"storm\", \"drum\", \"india\", \"beat\", \"black\", \"peter\", \"star\", \"hill\", \"alan\", \"outbreak\", \"lead\", \"break\", \"tuesday\", \"inquest\", \"thursday\", \"outback\", \"footage\", \"territory\", \"smith\", \"tour\", \"play\", \"best\", \"point\", \"open\", \"world\", \"league\", \"australia\", \"season\", \"australian\", \"news\", \"market\", \"live\", \"gold\", \"rise\", \"million\", \"street\", \"price\", \"industry\", \"rate\", \"wall\", \"fall\", \"video\", \"farm\", \"michael\", \"northern\", \"story\", \"trade\", \"flight\", \"share\", \"tourism\", \"dollar\", \"george\", \"super\", \"turn\", \"debate\", \"building\", \"disability\", \"spring\", \"scientist\", \"number\", \"record\", \"china\", \"coronavirus\", \"covid\", \"coast\", \"quarantine\", \"high\", \"australian\", \"australia\", \"business\", \"year\", \"court\", \"donald\", \"murder\", \"people\", \"charged\", \"face\", \"charge\", \"accused\", \"victim\", \"alleged\", \"shooting\", \"assault\", \"baby\", \"arrested\", \"food\", \"jailed\", \"jail\", \"sentenced\", \"appeal\", \"mother\", \"arrest\", \"teen\", \"kid\", \"get\", \"rape\", \"result\", \"killing\", \"online\", \"challenge\", \"hears\", \"guilty\", \"drug\", \"trial\", \"woman\", \"death\", \"police\", \"year\", \"family\", \"case\", \"crash\", \"house\", \"bushfire\", \"dy\", \"climate\", \"darwin\", \"week\", \"mark\", \"near\", \"close\", \"david\", \"station\", \"look\", \"white\", \"friday\", \"free\", \"girl\", \"find\", \"testing\", \"monday\", \"train\", \"bushfires\", \"plane\", \"truck\", \"festival\", \"month\", \"light\", \"start\", \"owner\", \"like\", \"adelaide\", \"road\", \"home\", \"woman\", \"police\", \"driver\", \"year\", \"death\", \"sydney\", \"election\", \"lockdown\", \"andrew\", \"commission\", \"president\", \"biden\", \"liberal\", \"travel\", \"medium\", \"right\", \"player\", \"social\", \"international\", \"kill\", \"security\", \"shot\", \"issue\", \"wednesday\", \"russia\", \"rugby\", \"airport\", \"leave\", \"human\", \"global\", \"mask\", \"paul\", \"america\", \"military\", \"cause\", \"leader\", \"dead\", \"state\", \"say\", \"warning\", \"australia\", \"win\", \"china\", \"australian\", \"queensland\", \"south\", \"north\", \"indigenous\", \"morrison\", \"student\", \"west\", \"killed\", \"city\", \"update\", \"program\", \"centre\", \"town\", \"bank\", \"east\", \"protester\", \"korea\", \"latest\", \"sport\", \"meet\", \"head\", \"extended\", \"hour\", \"great\", \"central\", \"prince\", \"refugee\", \"youth\", \"economy\", \"university\", \"victorian\", \"protest\", \"attack\", \"community\", \"school\", \"australia\", \"australian\", \"covid\", \"coast\", \"coronavirus\", \"national\", \"premier\", \"return\", \"tasmanian\", \"work\", \"rural\", \"show\", \"park\", \"risk\", \"young\", \"parliament\", \"weather\", \"sexual\", \"cricket\", \"law\", \"history\", \"club\", \"turnbull\", \"indonesia\", \"study\", \"join\", \"union\", \"kohler\", \"tree\", \"rollout\", \"money\", \"mount\", \"data\", \"recovery\", \"politics\", \"change\", \"worker\", \"say\", \"australia\", \"australian\", \"canberra\", \"restriction\", \"life\", \"water\", \"missing\", \"country\", \"claim\", \"concern\", \"officer\", \"john\", \"party\", \"search\", \"river\", \"western\", \"campaign\", \"crisis\", \"investigation\", \"fatal\", \"continues\", \"hold\", \"day\", \"opposition\", \"killer\", \"authority\", \"inside\", \"lake\", \"left\", \"russian\", \"continue\", \"robert\", \"long\", \"farmer\", \"amid\", \"police\", \"question\", \"crime\", \"victoria\", \"child\", \"scott\", \"deal\", \"beach\", \"abuse\", \"second\", \"violence\", \"daniel\", \"zealand\", \"body\", \"energy\", \"post\", \"domestic\", \"johnson\", \"coal\", \"prime\", \"allegation\", \"james\", \"lawyer\", \"pacific\", \"ship\", \"make\", \"research\", \"sign\", \"come\", \"economic\", \"target\", \"bos\", \"townsville\", \"island\", \"case\", \"covid\", \"coronavirus\", \"border\", \"minister\", \"say\", \"australia\"], \"Freq\": [47058.0, 24911.0, 22301.0, 21694.0, 37076.0, 18829.0, 33531.0, 21863.0, 20425.0, 22253.0, 16668.0, 16013.0, 14073.0, 13030.0, 17607.0, 15085.0, 11413.0, 11508.0, 11296.0, 11036.0, 11585.0, 11750.0, 11718.0, 10465.0, 11408.0, 42982.0, 14191.0, 11515.0, 10250.0, 9132.0, 21862.660399588385, 15085.157099037837, 11514.972695444834, 9788.846540233573, 10203.09082555446, 7914.3847210448885, 7865.283729757325, 7178.228288828103, 6708.873426511364, 6693.888240523028, 6556.972256677713, 6575.300060737024, 5882.123240852992, 5490.304680784199, 5483.069212257029, 5302.439972898668, 5065.482658219063, 5005.8199999664375, 4925.011649134383, 4921.187272041682, 4383.788052814413, 4067.0945544076685, 3982.757379878403, 3924.4799098209505, 3818.5600009891377, 3787.8388674912976, 3618.3355016390346, 3559.642649799978, 3606.3697813684485, 3495.2235382617837, 7395.8792591874435, 6824.331395394783, 5524.616473618732, 4147.00296960523, 8644.027100528458, 4591.356320399254, 4279.61491345949, 4328.567079987622, 24910.681299095242, 11717.89772921542, 8967.234734098687, 7814.266700761963, 7111.614577558511, 6142.757434773891, 5594.867052743246, 5448.249794748388, 5337.16171677031, 5201.708145610801, 4737.560833513462, 4445.370218466764, 3935.57479705299, 3867.0099783037194, 3708.165716429807, 3664.5919890474565, 3618.1992151633567, 3585.7203616712595, 3442.207966601554, 3392.365122943258, 3276.373622948109, 3255.3068681678437, 3235.2183422253165, 3181.6978606714947, 2824.634912377461, 2798.171338197868, 2843.1987033539863, 2617.843160909734, 2592.798104204129, 2542.325664927849, 8835.871678505273, 7938.8381185461385, 3795.4368060709653, 10663.323641437573, 3596.893756556953, 5010.245405638354, 11750.130981599335, 9528.06886292264, 8038.625039523218, 6377.697121658945, 6097.593078973428, 5805.067121112232, 5701.079459850085, 5693.770271828058, 4937.279855016391, 4524.306742351516, 4320.992487604077, 4236.366338238874, 4203.713502485736, 4097.64079916678, 4017.119193437806, 3981.6617951695494, 3865.82783509837, 3804.463425952041, 3532.8944631743498, 3441.01298296202, 3223.541700139637, 3017.2188525213774, 2925.1333419533444, 2892.3870397802752, 2622.8592354354023, 2611.521587722639, 2589.0916416494306, 2541.8967987563283, 2367.5182373388966, 2360.7352253668764, 3389.4836348446274, 9862.414774613726, 10735.88468505792, 28408.288538528308, 16261.748232652259, 6703.6019897793285, 4186.999255958173, 4459.912653398161, 9185.62556772926, 10467.768280645721, 4066.11611450055, 4150.402308259114, 16012.322378662371, 14073.106451987976, 11408.092503761458, 10249.947285107091, 9180.591476125539, 8823.550651019732, 6879.120173395437, 6219.767449284532, 6058.965856696956, 5765.318612685863, 5093.171983935373, 5019.047458451311, 4727.128040749857, 4691.370248031579, 4050.7550622882163, 4027.7656507637153, 3892.801830766965, 3859.9151482732295, 3802.123686104423, 3756.207007097387, 3631.6786698618903, 3562.1433709054554, 3307.9886655632463, 3220.7622895173613, 3168.9016993536084, 3132.7413575063492, 3029.7500922431764, 2993.4671268845395, 2914.0703452687517, 2830.4968736896335, 6036.746587406809, 5839.771058962794, 8046.9371134381545, 18015.897338512008, 14219.925080275865, 21646.33451467839, 9559.08309285969, 5473.393091551716, 4182.585324454623, 11584.419469449043, 9347.2827279064, 8483.175735580542, 8453.881483795869, 6286.806677465354, 6118.690808299961, 4722.691521031518, 4669.690285961589, 4591.003694264839, 4414.676467760419, 4265.2621272653705, 4241.688873566502, 4209.066584522167, 4021.0188229581154, 3982.4493035026453, 3967.1706338410745, 3901.6627192643778, 3818.0423046001465, 3813.8734973204896, 3774.4688765365463, 3688.4469980088866, 3545.400144101074, 3242.6044097159834, 3219.018014959493, 3211.09241120679, 3184.2568255363694, 3178.2846013489725, 3091.753055919826, 3088.1147866331726, 2892.6237754314757, 7977.831984383071, 4810.945318012506, 4932.118752674994, 4236.087175670478, 4232.041018261958, 3422.9499655069026, 3625.3196762041016, 3385.0609467020026, 21693.226888528556, 16667.483814499883, 9150.72005499322, 6779.466898643416, 5821.77423544174, 5808.044312520636, 5223.560723867048, 4969.365700807962, 4857.278202957101, 4722.122894794346, 4090.722234763799, 4035.1894442782923, 3856.5862441413346, 3828.2682139580406, 3462.9023899578906, 3421.9895293596624, 3364.671848894412, 3330.8564602271376, 3270.283889810329, 3168.6321599157995, 3036.3460206924456, 3024.807752757253, 2760.634027026367, 2586.97539557952, 2572.9074855838912, 2550.087840420871, 2519.192947507656, 2505.2194788509987, 2472.4814400234027, 2455.158383442143, 4385.281948040563, 4932.043407529157, 6081.984761178782, 5521.109967463587, 3120.9957432314036, 4705.103949589937, 3045.2661078119168, 3454.5412518500484, 3488.360490028422, 22301.01570130121, 13029.258743060405, 8666.780631026542, 7828.095911616532, 7652.485055004143, 6548.305589050044, 6512.96059035106, 5783.768182142148, 4895.627518007888, 4772.640478352324, 4535.387986673852, 4533.743446941238, 4275.568162762497, 4085.3305021426772, 3710.409381132052, 3491.195192231214, 3478.618972185779, 3424.8347171835508, 3387.577310767794, 3360.660820612917, 3346.327338108503, 3126.9912147316177, 2992.28658706672, 2974.369249107272, 2931.35595362737, 2917.383911090723, 2908.361002277694, 2847.9198036437897, 2767.716977798416, 2704.6933378656436, 8404.39897104587, 5693.672421967774, 6272.162059874141, 5494.536211155626, 6398.891494045048, 7925.534405944923, 4915.822097454389, 5039.689101619003, 3799.578390805574, 4013.268196456631, 10464.845681857578, 7200.974872164889, 7028.507456568048, 6601.370116882924, 6087.528890416418, 5905.593943612854, 5422.606186269654, 5336.167563301456, 5309.4434726214195, 5276.300808315744, 4969.1604409631855, 4776.453711674491, 4574.402400280942, 4327.435935487256, 3902.3135199111075, 3696.755231754797, 3673.0906821865906, 3259.368080313713, 3156.1097499923862, 3145.448981989345, 3118.186482330257, 3069.8012819342225, 3011.2862915245255, 2982.7765115078587, 2977.8166636732267, 2960.899452728325, 2827.9270717002555, 2809.1530140630643, 2722.5635194863485, 2620.3374211850864, 8023.648479814401, 5051.4552738717775, 5111.680517813847, 5131.940998567192, 3075.298187658875, 11507.69615767118, 11296.068958118869, 11035.26437533163, 9131.215392751885, 7463.875834922962, 7423.426179929853, 6918.168831491715, 6916.80614284396, 5808.579836381724, 5676.598237528759, 5617.325971037006, 5500.772097936506, 5122.845073497932, 4965.474856653157, 4783.100576036733, 4778.807057200001, 4544.683212449788, 4094.624356935334, 3254.7896513066903, 2937.895981966261, 2808.9361038757966, 2710.2175517934857, 2704.3398124934324, 2689.630725231377, 2671.8007638538866, 2566.1740815471135, 2533.778179977907, 2444.222380307495, 2429.9699790966783, 2375.6585067087017, 4065.7912765208785, 6485.225095276503, 4434.125437381447, 7602.352871666556, 3165.879688340525, 2802.6052516183036, 18828.899260326485, 11413.02973938839, 7454.394391912868, 4831.3516278510715, 4778.298792111952, 4681.392687770511, 4403.47399918418, 4378.752823661526, 3892.224587318681, 3868.4557803217604, 3699.722319833373, 3117.293570824638, 3083.4479922869714, 3049.216165747764, 3029.6737113211275, 2984.008031539475, 2797.423961076642, 2793.6344728095623, 2758.836742983509, 2708.908866469449, 2696.1062007086093, 2636.853845583688, 2501.7545916951167, 2416.5669215196403, 2401.0229376871266, 2291.9063565905813, 2256.639176859394, 2234.5298459500805, 2151.2690710353813, 2012.1724327394188, 7486.213580485199, 16242.144691523006, 15597.992512576346, 13241.453917982248, 5094.851404820849, 3380.1301221764725, 4005.6941703583443, 4088.5823832243136], \"Total\": [47058.0, 24911.0, 22301.0, 21694.0, 37076.0, 18829.0, 33531.0, 21863.0, 20425.0, 22253.0, 16668.0, 16013.0, 14073.0, 13030.0, 17607.0, 15085.0, 11413.0, 11508.0, 11296.0, 11036.0, 11585.0, 11750.0, 11718.0, 10465.0, 11408.0, 42982.0, 14191.0, 11515.0, 10250.0, 9132.0, 21863.47564588206, 15085.97234878974, 11515.787972337033, 9789.661794911957, 10203.949826862694, 7915.202038930967, 7866.09897985345, 7179.043581447765, 6709.688654213225, 6694.703524479864, 6557.787527128803, 6576.131757812965, 5882.938473743672, 5491.119968753794, 5483.887482650049, 5303.255187022189, 5066.297872269604, 5006.635281074129, 4925.826915928004, 4922.00257849434, 4384.603295305495, 4067.9098295877957, 3983.573410824125, 3925.2955797535146, 3819.3752789147043, 3788.6541549833487, 3619.150770806576, 3560.4580098085385, 3607.1984486292004, 3496.044786400602, 10735.498959887173, 10205.19380564093, 9557.917533224087, 5036.621587888274, 31527.79489098886, 8658.26694605904, 9331.789724990454, 12352.935091302701, 24911.510430836097, 11718.727111147471, 8968.063729521122, 7815.095646128665, 7112.4436244017525, 6143.586370994019, 5595.699506805111, 5449.07879748178, 5337.990659360422, 5202.537144519384, 4738.389790580336, 4446.1992601504235, 3936.4038144442866, 3867.838954310381, 3708.9947035371215, 3665.4210514355623, 3619.0283392760657, 3586.549340551526, 3443.036956807105, 3393.1940700033865, 3277.2026367880985, 3256.1358166902396, 3236.0473607763233, 3182.5269184589433, 2825.463961217134, 2799.0003042795065, 2844.0457287945164, 2618.6721237445936, 2593.6270846859584, 2543.154659054067, 10401.325678677142, 12599.420506391658, 4629.71130113349, 42982.64883756823, 4867.386500591101, 29434.347161708243, 11750.970163424527, 9528.908001812679, 8039.464209991559, 6378.5362805081495, 6098.43223612119, 5805.906313134176, 5701.918633841897, 5694.609412285324, 4938.119025039179, 4525.145897604217, 4321.831624959627, 4237.205491327192, 4204.55273713054, 4098.479973578272, 4017.9583994879454, 3982.5010876217516, 3866.6669991107874, 3805.302584261142, 3533.7336676013297, 3441.8521119779116, 3224.380893825553, 3018.0579822588497, 2925.9725964250792, 2893.243931999177, 2623.698427569933, 2612.360779364384, 2589.930829560679, 2542.736044342016, 2368.357393856464, 2361.5744197027825, 3391.1523670352026, 11800.275454766272, 14191.175172280058, 47058.603725005414, 37076.14718352055, 10503.934701371458, 5822.068659629821, 6712.436342424119, 29434.347161708243, 42982.64883756823, 8658.26694605904, 19421.77180010336, 16013.149427810682, 14073.933668664922, 11408.919526585012, 10250.774405329596, 9181.418504487989, 8824.377733189365, 6879.947209746951, 6220.594487970966, 6059.7929312815495, 5766.145654917885, 5093.999202632502, 5019.874502939778, 4727.955105953282, 4692.201259809697, 4051.5821397766917, 4028.5958452168557, 3893.628869266467, 3860.742192576554, 3802.950736713745, 3757.0340613448943, 3632.5060613042865, 3562.9704186063173, 3308.8157607199746, 3221.5893666718202, 3169.728762460166, 3133.568478801774, 3030.577153850143, 2994.2942318997684, 2914.897425822742, 2831.3239370386277, 6038.662520803164, 5902.832215458266, 8702.727999025838, 22253.117852672247, 17607.075142978894, 33531.90934572508, 19421.77180010336, 12122.350711115374, 20425.473795418315, 11585.371824824922, 9348.106852538875, 8483.999970793684, 8454.70558619057, 6287.630843622619, 6119.514931802453, 4723.515638442503, 4670.514426078464, 4591.827792856665, 4415.500591421476, 4266.086248002501, 4242.5129747313285, 4209.890717996904, 4021.842939115624, 3983.2734027174397, 3967.9947610640647, 3902.4868329781207, 3818.8664418047297, 3814.697704556588, 3775.292976840121, 3689.2711352159267, 3546.224326725805, 3243.428507992156, 3219.8421041253655, 3211.9164993756585, 3185.080957441507, 3179.1087039638755, 3092.577159561395, 3088.9389077965047, 2893.4478974756425, 10801.223182566482, 5736.256524522472, 13863.710350633728, 22253.117852672247, 33531.90934572508, 5747.151815934462, 19421.77180010336, 17607.075142978894, 21694.055972158483, 16668.313185941366, 9151.549665755945, 6780.296019717472, 5822.60332855292, 5808.873354512836, 5224.390045448708, 4970.194750355974, 4858.1073566316145, 4722.951942197352, 4091.5512813719065, 4036.0185103005774, 3857.4152915414534, 3829.0979441631625, 3463.731432768818, 3422.818585099174, 3365.5008958756503, 3331.685671414195, 3271.11290911549, 3169.461201922364, 3037.1750579148174, 3025.6367991941065, 2761.4696674400907, 2587.8044319115093, 2573.736926809993, 2550.9171807602347, 2520.0220178948516, 2506.0485280513335, 2473.3104862835366, 2455.987436763759, 5373.651749764328, 7096.283405883966, 11775.443536996396, 31527.79489098886, 5078.919966853677, 42982.64883756823, 5932.659870301538, 14191.175172280058, 29434.347161708243, 22301.84991936267, 13030.09290271775, 8667.614772049857, 7828.93009602427, 7653.319394428347, 6549.139746469509, 6513.794750888351, 5784.602362493438, 4896.461702626297, 4773.474766988426, 4536.222144756538, 4534.57760540076, 4276.402346094258, 4086.1646648189258, 3711.24353808754, 3492.031809884291, 3479.453094972805, 3425.6689725260912, 3388.4114981417615, 3361.494987837215, 3347.1615093450805, 3127.8253886002694, 2993.1207204813522, 2975.203440677052, 2932.1901121389787, 2918.2181366976197, 2909.195155343632, 2848.7539627332417, 2768.5511822413173, 2705.527505177402, 8431.451164393528, 7207.687705543594, 9214.126387709668, 8027.594664295442, 11297.56637039538, 42982.64883756823, 29434.347161708243, 37076.14718352055, 10503.934701371458, 47058.603725005414, 10465.669618044953, 7201.798222309813, 7029.330774709093, 6602.193495840687, 6088.35218973828, 5906.417197277891, 5423.429506925433, 5336.990857066435, 5310.266792088986, 5277.124118563366, 4969.983742774335, 4777.277227954642, 4575.2257606866915, 4328.259249383794, 3903.1368044935994, 3697.578535170887, 3674.003001652468, 3260.19134915639, 3156.9330555677825, 3146.2722699364213, 3119.009830481591, 3070.624575195027, 3012.1097138918176, 2983.599815231335, 2978.640388837366, 2961.7227572480524, 2828.7504108772077, 2809.976325595916, 2723.3868800461337, 2621.160731406473, 12352.935091302701, 9331.789724990454, 31527.79489098886, 42982.64883756823, 29434.347161708243, 11508.510822097564, 11296.883970080473, 11036.079048585716, 9132.03003277037, 7464.690478210535, 7424.240814007186, 6918.983486528569, 6917.620805341332, 5809.39450939715, 5677.412895846725, 5618.140637457735, 5501.586731235787, 5123.659712785033, 4966.289535652763, 4783.915229881831, 4779.621731555792, 4545.49787095475, 4095.4390265269935, 3255.604316000678, 2938.7106310727822, 2809.750779989994, 2711.0322057399612, 2705.1545004381574, 2690.4453988750206, 2672.6154469644257, 2566.98872657145, 2534.5928623768264, 2445.0370373265864, 2430.793371486782, 2376.4731722408187, 4154.585728510404, 9271.786467727226, 6556.053790480058, 33531.90934572508, 4543.686339090702, 3706.926379576491, 18829.73500998847, 11413.86542513348, 7455.230139231703, 4832.187309892358, 4779.1345082370535, 4682.228447049666, 4404.309693267073, 4379.588492453563, 3893.0603271398936, 3869.291480666262, 3700.5580030619717, 3118.1293182407994, 3084.2836884571857, 3050.051825529743, 3030.5093906310676, 2984.8437113396094, 2798.2596312373776, 2794.4701940145887, 2759.672426808843, 2709.7445590191687, 2696.941865500748, 2637.689540179305, 2502.590280368796, 2417.402824283825, 2401.85861164181, 2292.7420415016745, 2257.4748713623817, 2235.365533282777, 2152.104764372019, 2013.0081407995879, 7490.057403757724, 20425.473795418315, 37076.14718352055, 47058.603725005414, 9737.717729147444, 10205.19380564093, 31527.79489098886, 42982.64883756823], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -3.5356, -3.9067, -4.1767, -4.3391, -4.2977, -4.5517, -4.5579, -4.6493, -4.717, -4.7192, -4.7399, -4.7371, -4.8485, -4.9174, -4.9187, -4.9522, -4.9979, -5.0098, -5.0261, -5.0268, -5.1425, -5.2175, -5.2384, -5.2531, -5.2805, -5.2886, -5.3344, -5.3507, -5.3377, -5.369, -4.6195, -4.6999, -4.9112, -5.198, -4.4635, -5.0962, -5.1665, -5.1551, -3.2034, -3.9575, -4.2251, -4.3627, -4.4569, -4.6034, -4.6968, -4.7234, -4.744, -4.7697, -4.8631, -4.9268, -5.0486, -5.0662, -5.1081, -5.1199, -5.1327, -5.1417, -5.1825, -5.1971, -5.2319, -5.2384, -5.2446, -5.2612, -5.3803, -5.3897, -5.3737, -5.4563, -5.4659, -5.4856, -4.2398, -4.3469, -5.0848, -4.0518, -5.1386, -4.8072, -3.9528, -4.1624, -4.3324, -4.5638, -4.6087, -4.6579, -4.676, -4.6773, -4.8198, -4.9072, -4.9532, -4.9729, -4.9807, -5.0062, -5.0261, -5.0349, -5.0645, -5.0805, -5.1545, -5.1809, -5.2462, -5.3123, -5.3433, -5.3546, -5.4524, -5.4567, -5.4653, -5.4837, -5.5548, -5.5577, -5.196, -4.1279, -4.043, -3.07, -3.6278, -4.514, -4.9847, -4.9215, -4.199, -4.0683, -5.014, -4.9934, -3.6165, -3.7456, -3.9555, -4.0626, -4.1728, -4.2124, -4.4614, -4.5621, -4.5883, -4.638, -4.762, -4.7766, -4.8365, -4.8441, -4.991, -4.9966, -5.0307, -5.0392, -5.0543, -5.0665, -5.1002, -5.1195, -5.1935, -5.2202, -5.2365, -5.248, -5.2814, -5.2934, -5.3203, -5.3494, -4.592, -4.6252, -4.3046, -3.4986, -3.7352, -3.315, -4.1324, -4.69, -4.9589, -3.8663, -4.0809, -4.1779, -4.1813, -4.4775, -4.5046, -4.7636, -4.7749, -4.7919, -4.831, -4.8655, -4.871, -4.8787, -4.9244, -4.9341, -4.9379, -4.9546, -4.9762, -4.9773, -4.9877, -5.0108, -5.0503, -5.1396, -5.1469, -5.1494, -5.1577, -5.1596, -5.1872, -5.1884, -5.2538, -4.2393, -4.7451, -4.7202, -4.8723, -4.8733, -5.0855, -5.028, -5.0966, -3.2349, -3.4985, -4.0981, -4.398, -4.5503, -4.5527, -4.6588, -4.7087, -4.7315, -4.7597, -4.9032, -4.9169, -4.9622, -4.9695, -5.0698, -5.0817, -5.0986, -5.1087, -5.1271, -5.1586, -5.2013, -5.2051, -5.2965, -5.3615, -5.3669, -5.3758, -5.388, -5.3936, -5.4067, -5.4138, -4.8337, -4.7162, -4.5066, -4.6034, -5.1738, -4.7633, -5.1984, -5.0723, -5.0625, -3.1503, -3.6877, -4.0954, -4.1972, -4.2199, -4.3757, -4.3812, -4.4999, -4.6666, -4.692, -4.743, -4.7434, -4.802, -4.8475, -4.9438, -5.0047, -5.0083, -5.0239, -5.0348, -5.0428, -5.0471, -5.1149, -5.1589, -5.1649, -5.1795, -5.1843, -5.1874, -5.2084, -5.2369, -5.26, -4.1262, -4.5156, -4.4188, -4.5512, -4.3988, -4.1849, -4.6625, -4.6376, -4.9201, -4.8653, -3.8332, -4.207, -4.2312, -4.2939, -4.375, -4.4053, -4.4906, -4.5067, -4.5117, -4.518, -4.578, -4.6175, -4.6607, -4.7162, -4.8196, -4.8737, -4.8802, -4.9997, -5.0319, -5.0352, -5.044, -5.0596, -5.0788, -5.0883, -5.09, -5.0957, -5.1417, -5.1483, -5.1796, -5.2179, -4.0988, -4.5615, -4.5497, -4.5457, -5.0578, -3.7299, -3.7484, -3.7718, -3.9612, -4.1628, -4.1683, -4.2387, -4.2389, -4.4136, -4.4365, -4.447, -4.468, -4.5392, -4.5704, -4.6078, -4.6087, -4.6589, -4.7632, -4.9928, -5.0952, -5.1401, -5.1759, -5.178, -5.1835, -5.1901, -5.2305, -5.2432, -5.2792, -5.285, -5.3076, -4.7703, -4.3034, -4.6836, -4.1444, -5.0205, -5.1423, -3.2099, -3.7105, -4.1365, -4.5702, -4.5812, -4.6017, -4.6629, -4.6685, -4.7863, -4.7924, -4.837, -5.0083, -5.0192, -5.0304, -5.0368, -5.052, -5.1166, -5.1179, -5.1305, -5.1487, -5.1535, -5.1757, -5.2283, -5.2629, -5.2694, -5.3159, -5.3314, -5.3413, -5.3792, -5.4461, -4.1322, -3.3577, -3.3981, -3.5619, -4.5171, -4.9274, -4.7576, -4.7371], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 2.0147, 2.0147, 2.0147, 2.0147, 2.0147, 2.0146, 2.0146, 2.0146, 2.0146, 2.0146, 2.0146, 2.0146, 2.0146, 2.0146, 2.0146, 2.0146, 2.0146, 2.0146, 2.0146, 2.0146, 2.0146, 2.0145, 2.0145, 2.0145, 2.0145, 2.0145, 2.0145, 2.0145, 2.0145, 2.0145, 1.6421, 1.6123, 1.4666, 1.8204, 0.7207, 1.3804, 1.2352, 0.9661, 2.2164, 2.2164, 2.2164, 2.2164, 2.2164, 2.2163, 2.2163, 2.2163, 2.2163, 2.2163, 2.2163, 2.2163, 2.2163, 2.2163, 2.2163, 2.2162, 2.2162, 2.2162, 2.2162, 2.2162, 2.2162, 2.2162, 2.2162, 2.2162, 2.2162, 2.2162, 2.2162, 2.2162, 2.2162, 2.2161, 2.0534, 1.7546, 2.0178, 0.8225, 1.914, 0.4458, 2.2184, 2.2184, 2.2184, 2.2183, 2.2183, 2.2183, 2.2183, 2.2183, 2.2183, 2.2183, 2.2183, 2.2183, 2.2183, 2.2183, 2.2183, 2.2183, 2.2183, 2.2183, 2.2182, 2.2182, 2.2182, 2.2182, 2.2182, 2.2182, 2.2182, 2.2182, 2.2182, 2.2182, 2.2181, 2.2181, 2.218, 2.0391, 1.9395, 1.7138, 1.3943, 1.7694, 1.8888, 1.8096, 1.054, 0.806, 1.4627, 0.6753, 2.2452, 2.2452, 2.2452, 2.2452, 2.2452, 2.2452, 2.2451, 2.2451, 2.2451, 2.2451, 2.2451, 2.2451, 2.2451, 2.2451, 2.2451, 2.2451, 2.245, 2.245, 2.245, 2.245, 2.245, 2.245, 2.245, 2.245, 2.245, 2.245, 2.245, 2.245, 2.245, 2.245, 2.2449, 2.2345, 2.1669, 2.034, 2.0316, 1.8076, 1.5364, 1.4501, 0.6594, 2.3191, 2.3191, 2.3191, 2.3191, 2.319, 2.319, 2.319, 2.319, 2.319, 2.319, 2.319, 2.319, 2.319, 2.3189, 2.3189, 2.3189, 2.3189, 2.3189, 2.3189, 2.3189, 2.3189, 2.3189, 2.3189, 2.3189, 2.3189, 2.3189, 2.3189, 2.3189, 2.3189, 2.3189, 2.0162, 2.1432, 1.2856, 0.6603, 0.2493, 1.801, 0.6407, 0.6702, 2.3231, 2.3231, 2.3231, 2.3231, 2.323, 2.323, 2.323, 2.323, 2.323, 2.323, 2.323, 2.323, 2.323, 2.323, 2.3229, 2.3229, 2.3229, 2.3229, 2.3229, 2.3229, 2.3229, 2.3229, 2.3229, 2.3229, 2.3229, 2.3228, 2.3228, 2.3228, 2.3228, 2.3228, 2.1199, 1.9594, 1.6625, 0.5809, 1.8362, 0.111, 1.6563, 0.9102, 0.1904, 2.3801, 2.3801, 2.3801, 2.3801, 2.3801, 2.38, 2.38, 2.38, 2.38, 2.38, 2.38, 2.38, 2.38, 2.38, 2.38, 2.3799, 2.3799, 2.3799, 2.3799, 2.3799, 2.3799, 2.3799, 2.3799, 2.3799, 2.3799, 2.3799, 2.3799, 2.3799, 2.3799, 2.3799, 2.377, 2.1444, 1.9956, 2.001, 1.8117, 0.6895, 0.5905, 0.3845, 1.3633, -0.0816, 2.4538, 2.4538, 2.4538, 2.4538, 2.4538, 2.4538, 2.4538, 2.4538, 2.4538, 2.4538, 2.4538, 2.4537, 2.4537, 2.4537, 2.4537, 2.4537, 2.4537, 2.4537, 2.4537, 2.4537, 2.4537, 2.4536, 2.4536, 2.4536, 2.4536, 2.4536, 2.4536, 2.4536, 2.4536, 2.4536, 2.0224, 1.8402, 0.6346, 0.3286, 0.1952, 2.4622, 2.4622, 2.4622, 2.4621, 2.4621, 2.4621, 2.4621, 2.4621, 2.4621, 2.4621, 2.4621, 2.4621, 2.4621, 2.4621, 2.4621, 2.4621, 2.462, 2.462, 2.462, 2.4619, 2.4619, 2.4619, 2.4619, 2.4619, 2.4619, 2.4619, 2.4619, 2.4619, 2.4619, 2.4619, 2.4406, 2.1048, 2.0712, 0.9782, 2.1009, 2.1826, 2.4898, 2.4898, 2.4897, 2.4897, 2.4897, 2.4897, 2.4896, 2.4896, 2.4896, 2.4896, 2.4896, 2.4896, 2.4896, 2.4896, 2.4896, 2.4896, 2.4895, 2.4895, 2.4895, 2.4895, 2.4895, 2.4895, 2.4895, 2.4895, 2.4895, 2.4895, 2.4895, 2.4895, 2.4894, 2.4894, 2.4893, 2.2607, 1.624, 1.2218, 1.8421, 1.3849, 0.4267, 0.1372]}, \"token.table\": {\"Topic\": [1, 10, 4, 1, 2, 5, 1, 6, 2, 10, 4, 6, 3, 9, 6, 1, 4, 4, 4, 4, 6, 7, 2, 3, 6, 7, 8, 10, 2, 3, 4, 5, 6, 7, 8, 9, 4, 7, 10, 2, 2, 6, 2, 10, 6, 7, 10, 10, 2, 1, 1, 3, 5, 5, 1, 3, 1, 6, 7, 9, 10, 9, 9, 1, 4, 10, 6, 7, 7, 4, 1, 8, 4, 4, 10, 3, 6, 1, 7, 7, 9, 5, 5, 8, 10, 3, 7, 10, 6, 1, 7, 9, 9, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 9, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 5, 8, 7, 9, 9, 10, 5, 8, 5, 9, 5, 6, 10, 4, 5, 9, 3, 3, 3, 10, 4, 4, 5, 2, 4, 2, 5, 7, 10, 7, 6, 1, 10, 1, 7, 4, 3, 1, 4, 5, 6, 7, 8, 10, 3, 1, 9, 9, 1, 5, 2, 1, 5, 3, 4, 2, 5, 5, 1, 3, 4, 5, 6, 3, 1, 7, 4, 10, 7, 1, 4, 3, 4, 2, 8, 9, 2, 4, 5, 6, 7, 8, 10, 1, 1, 4, 5, 7, 9, 7, 5, 1, 6, 2, 7, 8, 3, 2, 9, 6, 2, 9, 1, 10, 6, 4, 4, 10, 9, 10, 8, 4, 6, 7, 9, 4, 8, 1, 7, 9, 7, 8, 10, 2, 6, 7, 2, 6, 6, 9, 6, 9, 5, 5, 3, 6, 5, 9, 5, 10, 5, 3, 6, 6, 7, 1, 3, 6, 3, 1, 10, 9, 5, 8, 5, 7, 4, 8, 4, 8, 5, 3, 7, 3, 3, 8, 9, 4, 2, 10, 9, 2, 2, 5, 10, 2, 8, 8, 9, 1, 6, 4, 2, 1, 5, 2, 6, 2, 4, 5, 7, 9, 10, 8, 10, 8, 6, 3, 10, 7, 7, 1, 7, 8, 7, 1, 1, 3, 7, 7, 1, 9, 4, 3, 2, 3, 8, 7, 1, 10, 9, 4, 8, 1, 6, 3, 8, 9, 1, 5, 9, 9, 8, 2, 6, 8, 6, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 4, 5, 7, 10, 3, 10, 9, 2, 5, 10, 6, 4, 1, 8, 3, 10, 4, 6, 8, 10, 2, 6, 7, 1, 7, 3, 2, 5, 1, 6, 9, 5, 1, 2, 3, 3, 7, 8, 3, 6, 10, 1, 8, 4, 2, 2, 5, 2, 1, 2, 3, 7, 10, 3, 5, 6, 8, 4, 10, 5, 2, 2, 3, 8, 8, 7, 7, 2, 4, 10, 5, 7, 3, 10, 3, 5, 6, 9, 8, 6, 5, 7, 9, 5, 2, 6, 4, 5, 9, 8, 1, 8, 2, 3, 6, 3, 4, 5, 10, 8, 7, 10], \"Freq\": [0.9998321264749822, 0.9997376362423238, 0.9999044322898534, 0.9998624059544587, 0.261359287951425, 0.7386200493363331, 0.9998949132732626, 0.9997895321757468, 0.999885128767022, 0.9998317412668792, 0.9998013135660374, 0.9995816010585602, 0.32351778490284366, 0.6763214796130168, 0.99980885499487, 0.9997960400136645, 0.9997500002551791, 0.9998606853517252, 0.9997439880040981, 0.9998257918720347, 0.3191838136627771, 0.6806939405960346, 0.24807684701553787, 0.2435401326604755, 0.1094627745670173, 0.18439998963191906, 0.11939701574451282, 0.09513141024538443, 0.17020931269430747, 0.3120843805209398, 0.05850308112966017, 0.06920486426313459, 0.11850101450653582, 0.16701576471161986, 0.10446978773153602, 0.9998344516208332, 0.9997979875164044, 0.9997149735964013, 0.9997626121978576, 0.9999177377553212, 0.9997582209525567, 0.9999253414378875, 0.9997302729634338, 0.9998492111023499, 0.18587517633441086, 0.29082790020942073, 0.5232232173612283, 0.9994866586467777, 0.9996988249559579, 0.999669940842112, 0.999827899157948, 0.9996405967487415, 0.9998821345123613, 0.9996547520368133, 0.5302446815975884, 0.46960899049788596, 0.6889293201587465, 0.16757488466273457, 9.31489075390409e-05, 0.0013040847055465726, 0.14205208399703736, 0.9998086860159825, 0.9999556135363246, 0.9998602890891324, 0.2047932910588492, 0.7951835126411256, 0.9995979471437931, 0.9995941217678718, 0.9998726220056148, 0.9996921243901099, 0.3504430297741877, 0.6495622247419917, 0.9998623231082924, 0.9999544183191537, 0.9999241777346022, 0.7565264940828065, 0.24346116216990465, 0.823369381168604, 0.17650720517455726, 0.9999057068850249, 0.9998578567891535, 0.9998996691061691, 0.9998866286141035, 0.9997270003176326, 0.9997173348351861, 0.6382370217062264, 0.3617691948812143, 0.999676351945294, 0.9998963816494314, 0.31541203883420366, 0.6845138836468992, 0.9999102573906837, 0.9996736162373618, 0.9998143767048999, 0.00847878960310045, 0.00023375109181479937, 0.6036728196613473, 0.00014875069479123595, 0.00025500119107069023, 0.01772258277941297, 0.08527664831388998, 0.0005100023821413805, 0.002295010719636212, 0.28137256424725077, 0.9998481354076554, 0.9998328699138039, 0.9999282197536553, 0.002751094915421431, 0.0007012594882446785, 0.43861083837826775, 2.697151877864148e-05, 8.091455633592444e-05, 0.00024274366900777332, 0.13593645464435306, 0.00045851581923690514, 0.0005394303755728296, 0.4207017499092498, 0.9998815899182465, 0.9997090633182444, 0.24386780513922163, 0.7561520550942901, 0.9998699203429243, 0.9997276366018524, 0.9999158541472336, 0.9996525502414298, 0.9997453759864772, 0.9997327948103651, 0.3049483618714684, 0.6950117009011471, 0.9997542914178994, 0.8076298808590281, 0.1922522606686224, 5.6795350271380315e-05, 0.9998618952760147, 0.9997105305744755, 0.999649449326332, 0.9996551450303438, 0.9999336597225124, 0.4042002150629268, 0.5955993698495042, 0.01050343254508152, 0.9893555816657432, 0.9998144134331362, 0.9999165451495173, 0.9996649268433133, 0.9997896448955398, 0.999800913111214, 0.9999212166266186, 0.9998731121724543, 0.9996378218715327, 0.9998713621092352, 0.9997361142334614, 0.9999571943540059, 0.999715498497852, 0.2128300080968879, 0.45148009081948354, 0.08480203423395379, 0.01922069452968019, 0.1240683458053176, 0.10740491106284808, 0.00016498450240068832, 0.9998828898563941, 0.300481467050322, 0.6994337091964602, 0.9998928011077323, 0.999932398592942, 0.999714656537355, 0.9998598038746707, 0.9997963067921336, 0.999773115447232, 0.9997923817496331, 0.9998563179131983, 0.9998344339349066, 0.9997493038363292, 0.9996803124996213, 0.9997633176270189, 0.9996675989288938, 0.9998170571712468, 0.9998752505776556, 0.9997136743843877, 0.9999159242050895, 0.9999782447269701, 0.9995955097857852, 0.9997246872469796, 0.00016559958377455352, 0.9996529867645055, 0.9999355461638627, 0.999532396480209, 0.6644383309547071, 0.33549666397085204, 0.9997318131686268, 0.999843536745634, 0.9997581826991511, 0.0871339612158574, 0.1955464973975078, 0.3557489211230204, 0.08316676927308243, 0.12803210360773748, 0.15010411696208548, 0.00028852305038363374, 0.9997763397848256, 0.5780547886916431, 0.17796763720624162, 0.1478355504834917, 0.0006277518067239563, 0.09541827462204136, 0.9996255678985203, 0.9998815960754049, 0.9998560561674182, 0.9996891450135916, 0.9998967533523619, 0.9998811975566442, 0.9997044423966682, 0.9997733904279129, 0.9996330294701345, 0.9997697210928251, 0.9997132629723311, 0.9999045555871425, 0.9998904694339575, 0.0004005309757031922, 0.9994582947046989, 0.9997941968475363, 0.9998384876197547, 0.9998520960553631, 0.9997563381790133, 0.9999272739442595, 0.9998319125383203, 0.9996762336329555, 0.9997534584035598, 0.9997888309809766, 0.9998958679515565, 0.999573221996019, 0.9998095564571224, 0.9996315825128482, 0.9999017433775685, 0.9998697798302096, 0.9996148301855728, 0.9998047176970524, 0.9997087459265351, 0.999725229074936, 0.9998468331258364, 0.8160186413628894, 0.18386007244390756, 0.8197055395378264, 0.18014082212768043, 0.9998299212026015, 0.9997660916726995, 0.9997596169937026, 0.9999022253663674, 0.999651253207387, 0.9998452028543409, 0.9999422585909417, 0.99993993741213, 0.021181413924403904, 0.9786776024616621, 0.9997884225371704, 0.9997641322379351, 0.9998898566557056, 0.9999047108217956, 0.9996404505927702, 0.9997984433868897, 0.9998527477092765, 0.9997438223526673, 0.9997614710276573, 0.9994701488992974, 0.9998438980780441, 0.6686791186883709, 0.3312039011088356, 0.9999075007580622, 0.9996575161588643, 0.9997559672841478, 0.9996606185349916, 0.9998276049436396, 0.9997247665770366, 0.9997347200112381, 0.9999194028336452, 0.9999360176587461, 0.9998197247601592, 0.9999174397168035, 0.9999290725227152, 0.9998741776560189, 0.9993652992250878, 0.0002948850100988751, 0.9999320911333338, 0.9995677672935478, 0.849507098707035, 0.1504615900267666, 0.9996192572933011, 0.9996763456588991, 0.9997158521073445, 0.9996960419663417, 0.9996507653676943, 0.9998749920712754, 0.9998143416219043, 0.9998020631806361, 0.9997969724271177, 0.9996677619359545, 0.9995944408867882, 0.9999244539681614, 0.9998974153914787, 0.9999069157650899, 0.999867884249306, 0.9997433341354578, 0.9997476447895425, 0.9995459737181315, 0.6455343707637575, 0.12620814270868622, 0.0014314723180569326, 0.2267094283722667, 5.9644679919038856e-05, 0.9995571689318532, 0.9995837968919689, 0.99988916347207, 0.999849651651958, 0.9998929843574506, 0.9995498519067652, 0.9995825751741101, 0.9997305809289012, 0.9997011518832178, 0.789989832053991, 0.20991475516292385, 0.9997045244887603, 0.9998404753427457, 0.15097726450651108, 0.7191601894070102, 0.12985075309092423, 0.9999618901855343, 0.3030578911561862, 0.6967910554832865, 0.9997700868071752, 0.9997467711251424, 0.16414871054705954, 0.8357432025891074, 0.9998579415767299, 0.9995891800722145, 0.9998546350309863, 0.9998333648493423, 0.9999217509817031, 0.9998185842097853, 0.9999529436414796, 0.9998381654158922, 0.9998652634822356, 0.9999291234034495, 0.9997614447374145, 0.9998712418813868, 0.14556531710713747, 0.8387002881466328, 0.015689674897775296, 0.9998008930854572, 0.9997850063271263, 0.9999376270062471, 0.9996131082692269, 0.9999293654234104, 0.9998544857018333, 0.9995758602791063, 0.2741707762908148, 0.09965809568553217, 0.04120173975032027, 3.171804445752138e-05, 0.00025374435566017105, 0.17511532344997555, 0.06045459273603575, 0.1621426432668493, 0.059947104024715404, 0.12706248609683066, 0.24642475279413373, 0.041159306770571905, 0.1452525213129215, 0.5664051699459992, 0.0007081171057302693, 0.999756764090096, 0.9998349964778109, 0.9998933523609733, 0.7390002827108914, 0.2609203111044849, 0.9997026337023767, 0.9997608447310828, 0.9998077590940982, 0.999897364207385, 0.9997320873874195, 0.9997524263244937, 0.9997385817516423, 0.9998038471164296, 0.999851167510826, 0.9999208052902901, 0.9996425219879104, 0.9996426208750399, 0.9998923394267752, 0.9999161247179196, 0.999879909630261, 0.9998785572112516, 0.9998490963157034, 0.9997830948185044, 0.9998133726236674, 0.328989730860546, 0.5164985914026434, 0.15447401147014278, 0.9998790870565667, 0.9996820329189215, 0.9998020220441153, 0.9998275002447998, 0.9998388903979716, 0.9998259700489482, 0.9995956262436095, 0.9995700563006736, 0.9999513243553977, 0.9998364771768489, 0.9999315746053222, 0.9998192273762593, 0.9997276377594241, 0.9998357929092345, 0.9998813869355522, 0.9998171009577627, 0.999651176500557, 0.9998273384276872, 0.9996323094302145, 0.9998818707100385, 0.9999059148177146, 0.9994991869237114, 0.999657692330032, 0.9996554508548333, 0.9997720600739498, 0.99979896257257, 0.9246525917965909, 0.07526375638458643, 0.9997384641550322, 0.9999795102413596, 0.9996480985234701, 0.9997338003626508, 0.999634576922395, 0.9997965966923889, 0.9998050268657803, 0.9999005405890674, 0.9999379530608935, 0.9998691487827156, 0.9999609654629722, 0.0030836921774272264, 0.9967441945807081, 0.999868538423681, 0.9998656283679216, 0.9998075758077144, 0.3853181410165704, 0.6145007246360328, 0.9998872065940789, 0.9997326452090392, 0.9996597766122995, 0.9998908358769247, 0.9998779895715562, 0.9997403422326657, 0.9997904097379273, 0.48662826845208357, 0.5132605048273621, 0.8095944181519069, 0.1903553483176886, 4.4937523210030355e-05, 0.9999421535208043, 0.458647282689857, 0.5412680899220719, 0.6301083447427255, 0.18088133488709804, 0.18897694531205814, 0.21367772429382134, 0.49217960639147906, 0.18664620495544634, 0.10740523683780995, 0.9997869827318611, 0.999735335959825, 0.9996662229576875], \"Term\": [\"aboriginal\", \"abuse\", \"accused\", \"action\", \"adelaide\", \"adelaide\", \"aged\", \"airport\", \"alan\", \"allegation\", \"alleged\", \"america\", \"amid\", \"amid\", \"andrew\", \"announces\", \"appeal\", \"arrest\", \"arrested\", \"assault\", \"attack\", \"attack\", \"australia\", \"australia\", \"australia\", \"australia\", \"australia\", \"australia\", \"australian\", \"australian\", \"australian\", \"australian\", \"australian\", \"australian\", \"australian\", \"authority\", \"baby\", \"bank\", \"beach\", \"beat\", \"best\", \"biden\", \"black\", \"body\", \"border\", \"border\", \"border\", \"bos\", \"break\", \"briefing\", \"budget\", \"building\", \"bushfire\", \"bushfires\", \"business\", \"business\", \"call\", \"call\", \"call\", \"call\", \"call\", \"campaign\", \"canberra\", \"care\", \"case\", \"case\", \"cause\", \"central\", \"centre\", \"challenge\", \"change\", \"change\", \"charge\", \"charged\", \"child\", \"china\", \"china\", \"christmas\", \"christmas\", \"city\", \"claim\", \"climate\", \"close\", \"club\", \"coal\", \"coast\", \"coast\", \"come\", \"commission\", \"community\", \"community\", \"concern\", \"continue\", \"continues\", \"coronavirus\", \"coronavirus\", \"coronavirus\", \"coronavirus\", \"coronavirus\", \"coronavirus\", \"coronavirus\", \"coronavirus\", \"coronavirus\", \"coronavirus\", \"council\", \"country\", \"court\", \"covid\", \"covid\", \"covid\", \"covid\", \"covid\", \"covid\", \"covid\", \"covid\", \"covid\", \"covid\", \"crash\", \"cricket\", \"crime\", \"crime\", \"crisis\", \"daniel\", \"darwin\", \"data\", \"david\", \"day\", \"dead\", \"dead\", \"deal\", \"death\", \"death\", \"death\", \"debate\", \"disability\", \"dollar\", \"domestic\", \"donald\", \"driver\", \"driver\", \"drug\", \"drug\", \"drum\", \"dy\", \"east\", \"economic\", \"economy\", \"election\", \"emergency\", \"energy\", \"expert\", \"extended\", \"face\", \"fall\", \"family\", \"family\", \"family\", \"family\", \"family\", \"family\", \"family\", \"farm\", \"farmer\", \"farmer\", \"fatal\", \"federal\", \"festival\", \"final\", \"finance\", \"find\", \"flight\", \"food\", \"footage\", \"free\", \"friday\", \"funding\", \"george\", \"get\", \"girl\", \"global\", \"gold\", \"government\", \"great\", \"guilty\", \"guilty\", \"head\", \"health\", \"hears\", \"high\", \"high\", \"hill\", \"history\", \"hold\", \"home\", \"home\", \"home\", \"home\", \"home\", \"home\", \"home\", \"hong\", \"hospital\", \"hospital\", \"hospital\", \"hospital\", \"hospital\", \"hour\", \"house\", \"housing\", \"human\", \"india\", \"indigenous\", \"indonesia\", \"industry\", \"inquest\", \"inside\", \"international\", \"interview\", \"investigation\", \"island\", \"island\", \"issue\", \"jail\", \"jailed\", \"james\", \"john\", \"johnson\", \"join\", \"kid\", \"kill\", \"killed\", \"killer\", \"killing\", \"kohler\", \"kong\", \"korea\", \"lake\", \"latest\", \"law\", \"lawyer\", \"lead\", \"leader\", \"leader\", \"league\", \"league\", \"leave\", \"left\", \"liberal\", \"life\", \"light\", \"like\", \"live\", \"lockdown\", \"long\", \"long\", \"look\", \"make\", \"mark\", \"market\", \"mask\", \"medium\", \"meet\", \"mental\", \"michael\", \"military\", \"million\", \"minister\", \"minister\", \"missing\", \"monday\", \"money\", \"month\", \"morrison\", \"mother\", \"mount\", \"murder\", \"national\", \"near\", \"news\", \"north\", \"northern\", \"number\", \"number\", \"officer\", \"online\", \"open\", \"open\", \"opposition\", \"outback\", \"outbreak\", \"owner\", \"pacific\", \"pandemic\", \"park\", \"parliament\", \"party\", \"patient\", \"paul\", \"people\", \"peter\", \"plan\", \"plane\", \"play\", \"player\", \"point\", \"police\", \"police\", \"police\", \"police\", \"police\", \"politics\", \"post\", \"premier\", \"president\", \"price\", \"prime\", \"prince\", \"program\", \"project\", \"protest\", \"protest\", \"protester\", \"public\", \"quarantine\", \"quarantine\", \"quarantine\", \"queensland\", \"question\", \"question\", \"rape\", \"rate\", \"record\", \"record\", \"recovery\", \"refugee\", \"regional\", \"research\", \"restriction\", \"result\", \"return\", \"review\", \"right\", \"rise\", \"risk\", \"river\", \"road\", \"road\", \"road\", \"robert\", \"rollout\", \"royal\", \"rugby\", \"rural\", \"russia\", \"russian\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"school\", \"school\", \"school\", \"school\", \"school\", \"scientist\", \"scott\", \"search\", \"season\", \"season\", \"second\", \"security\", \"sentenced\", \"service\", \"sexual\", \"share\", \"ship\", \"shooting\", \"shot\", \"show\", \"sign\", \"smith\", \"social\", \"south\", \"speaks\", \"sport\", \"spring\", \"star\", \"start\", \"state\", \"state\", \"state\", \"station\", \"stop\", \"storm\", \"story\", \"street\", \"student\", \"study\", \"super\", \"sydney\", \"target\", \"tasmania\", \"tasmanian\", \"teen\", \"territory\", \"test\", \"testing\", \"thursday\", \"told\", \"tour\", \"tourism\", \"town\", \"townsville\", \"trade\", \"train\", \"travel\", \"tree\", \"trial\", \"trial\", \"truck\", \"trump\", \"tuesday\", \"turn\", \"turnbull\", \"union\", \"university\", \"update\", \"vaccine\", \"victim\", \"victoria\", \"victorian\", \"victorian\", \"video\", \"violence\", \"wall\", \"warning\", \"warning\", \"water\", \"weather\", \"wednesday\", \"week\", \"west\", \"western\", \"white\", \"win\", \"win\", \"woman\", \"woman\", \"woman\", \"work\", \"worker\", \"worker\", \"world\", \"world\", \"world\", \"year\", \"year\", \"year\", \"year\", \"young\", \"youth\", \"zealand\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [6, 10, 8, 5, 7, 3, 4, 9, 2, 1]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el2768311892900688611380815\", ldavis_el2768311892900688611380815_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el2768311892900688611380815\", ldavis_el2768311892900688611380815_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el2768311892900688611380815\", ldavis_el2768311892900688611380815_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "vis = pyLDAvis.gensim.prepare(topic_model=lda_model, corpus=bow_corpus, dictionary=dictionary)\n",
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.display(vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some other useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1287 : canberra : 0.023995733\n",
      "363 : restriction : 0.02355445\n",
      "1465 : life : 0.023010625\n",
      "55 : water : 0.01904032\n",
      "237 : police : 0.01585235\n",
      "313 : missing : 0.0155636\n",
      "426 : country : 0.015479255\n",
      "372 : claim : 0.014425697\n",
      "368 : concern : 0.014422855\n",
      "455 : farmer : 0.013522927\n",
      "2214 : officer : 0.012111993\n",
      "3361 : john : 0.011836786\n",
      "1737 : party : 0.011713193\n",
      "541 : search : 0.011470156\n",
      "293 : river : 0.010682106\n",
      "342 : western : 0.010353959\n",
      "396 : campaign : 0.009973674\n",
      "888 : crisis : 0.009964721\n",
      "277 : investigation : 0.0094765285\n",
      "4403 : amid : 0.0092459945\n"
     ]
    }
   ],
   "source": [
    "#get the top 20 words and their weights for a specific topic\n",
    "topic_id=1\n",
    "top_terms=20\n",
    "for wordid, score in lda_model.get_topic_terms(topic_id, top_terms):\n",
    "    print(wordid, \":\", dictionary[wordid], \":\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Utility function to get the id for a word\n",
    "\n",
    "def get_id_for_word(dictionary, word):\n",
    "    for k, v in dictionary.iteritems():\n",
    "        if (v==word):\n",
    "            return k\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 7\n",
      "18888 : coronavirus : 0.04642302\n",
      "18889 : covid : 0.026573915\n",
      "1363 : news : 0.019201318\n",
      "1300 : china : 0.0175439\n",
      "37 : australia : 0.017105762\n",
      "26 : record : 0.016116532\n",
      "1188 : market : 0.015570165\n",
      "16 : australian : 0.0150105655\n",
      "367 : live : 0.01313621\n",
      "224 : coast : 0.010954601\n",
      "225 : gold : 0.010422028\n",
      "12 : rise : 0.009964299\n",
      "41 : million : 0.009486272\n",
      "3204 : street : 0.009316342\n",
      "852 : price : 0.009304398\n",
      "567 : industry : 0.008068189\n",
      "110 : rate : 0.0073933345\n",
      "693 : high : 0.007288106\n",
      "2262 : wall : 0.0070610913\n",
      "1773 : fall : 0.0069228006\n"
     ]
    }
   ],
   "source": [
    "top_terms=20\n",
    "index=get_id_for_word(dictionary,'market')\n",
    "for topic_id, score in lda_model.get_term_topics(index):\n",
    "    print(\"Topic:\", topic_id)\n",
    "    for wordid, score in lda_model.get_topic_terms(topic_id, top_terms):\n",
    "        print(wordid, \":\", dictionary[wordid], \":\", score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and loading your model for re-use\n",
    "\n",
    "Building a model takes time.Once you have a stable model, you can save it to disk and reload it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LdaModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m lda_model\u001b[38;5;241m.\u001b[39msave(temp_file)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Load a potentially pretrained model from disk.\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m loaded_lda \u001b[38;5;241m=\u001b[39m LdaModel\u001b[38;5;241m.\u001b[39mload(temp_file)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LdaModel' is not defined"
     ]
    }
   ],
   "source": [
    "# Save model to disk.\n",
    "temp_file = \"./model\"\n",
    "lda_model.save(temp_file)\n",
    "\n",
    "# Load a potentially pretrained model from disk.\n",
    "loaded_lda = LdaModel.load(temp_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing model on unseen document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_document = 'How a Pentagon deal became an identity crisis for Google'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to compare any new text against the topic model, we first need to process it in the same way as we processed the input texts for the model.\n",
    "We apply the same preprocessing function and next apply the *doc2bow* function to represent it using the same vector representation as we used for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_vector = dictionary.doc2bow(preprocess(unseen_document))\n",
    "print(bow_vector)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now pass this representation of the unseen document into the model to compare it against all the topics.\n",
    "The next function returns in index to the topics and a similarity score for the new document. We print the scores and the topics with the top 5 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, score in sorted(lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n",
    "    print(\"Score: {}\\t Topic_id {}\\t Topic: {}\".format(score, index, lda_model.print_topic(index, 5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This text matches best with topic 5 although the score is not very high!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating the model with a new document\n",
    "\n",
    "We can also use the unseen documents to extend our model and update the topics. This is useful when processing texts in a stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the model by incrementally training on the new corpus.\n",
    "\n",
    "other_texts = [['computer', 'time', 'graph'],['survey', 'response', 'eps'],['human', 'system', 'computer']]\n",
    "other_corpus = [dictionary.doc2bow(text) for text in other_texts]\n",
    "\n",
    "# Update the model by incrementally training on the new corpus.\n",
    "lda_model.update(other_corpus)  # update the LDA model with additional documents\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
